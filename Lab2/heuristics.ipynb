{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Welcome FSP solved with diverse heuristics</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.benchmarks import benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Reading the data from the benchmark file\n",
    "'''\n",
    "\n",
    "def read_flow_shop_data(file_path, machine_count, job_count):\n",
    "    instances = []\n",
    "    with open(file_path) as p:\n",
    "        lines = p.readlines()\n",
    "        line_count = len(lines)\n",
    "\n",
    "        instance_count = line_count // (machine_count + 3)\n",
    "\n",
    "        for i in range(instance_count):\n",
    "            # recover the data of each instance\n",
    "            params_line = lines[i * (machine_count + 3) + 1]\n",
    "            job_count, machine_count, initial_seed, upper_bound, lower_bound = list(\n",
    "                map(lambda x: int(x), params_line.split()))\n",
    "\n",
    "            # processing_times = [list(map(int, lines[i * (machine_count + 3) + 3])) for line in lines]\n",
    "            processing_times = np.array([list(map(lambda x: int(x), line.strip().split())) for\n",
    "                                         line in lines[\n",
    "                                                 i * (machine_count + 3) + 3:  # start\n",
    "                                                 i * (machine_count + 3) + 3 + machine_count  # end\n",
    "                                                 ]\n",
    "                                         ])\n",
    "\n",
    "            record = (machine_count, job_count, processing_times)\n",
    "            instances.append(record)\n",
    "\n",
    "    return instances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Cost calculation function :\n",
    "used to calculate the cost of current node, which is the correct cost starting for the actual path of executed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_cost(machine_job_matrix, jobs_sequence):\n",
    "    nb_jobs = len(jobs_sequence)\n",
    "    nb_machines = machine_job_matrix.shape[0]\n",
    "\n",
    "    incremental_cost = np.zeros((nb_machines, nb_jobs))\n",
    "\n",
    "    # evaluate the first machines\n",
    "    incremental_cost[0, 0] = machine_job_matrix[0][jobs_sequence[0]]\n",
    "\n",
    "    for i in range(1, nb_jobs):\n",
    "        incremental_cost[0][i] = incremental_cost[0][i - 1] + \\\n",
    "            machine_job_matrix[0][jobs_sequence[i]]\n",
    "\n",
    "    # evaluate the rest of machines\n",
    "    for i in range(1, nb_machines):\n",
    "        incremental_cost[i, 0] = incremental_cost[i - 1, 0] + \\\n",
    "            machine_job_matrix[i, jobs_sequence[0]]\n",
    "        for j in range(1, nb_jobs):\n",
    "            incremental_cost[i, j] = machine_job_matrix[i, jobs_sequence[j]] + \\\n",
    "                max(incremental_cost[i - 1, j], incremental_cost[i, j - 1])\n",
    "    return incremental_cost[-1,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gantt graph generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gantt_chart(current_instance, solution):\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    df = pd.DataFrame(columns=['Machine', 'Job', 'Start', 'Finish'])\n",
    "\n",
    "    machines, jobs = current_instance.shape\n",
    "    machine_times = np.zeros((machines, jobs))\n",
    "    start_time_m = np.zeros(machines)\n",
    "    for job in solution:\n",
    "\n",
    "        for machine_index in range(machines):\n",
    "            start_time = start_time_m[machine_index]\n",
    "            if machine_index > 0:\n",
    "                start_time = max(start_time, start_time_m[machine_index-1])\n",
    "            end_time = start_time + \\\n",
    "                current_instance[machine_index, job]\n",
    "            start_time_m[machine_index] = end_time\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame({'Machine': f'Machine {machine_index + 1}',\n",
    "                                                'Job': f'Job {job + 1}',\n",
    "                                                'Start': start_time,\n",
    "                                                'Finish': end_time}, index=[0])], ignore_index=True)\n",
    "\n",
    "            machine_times[machine_index, job] = end_time\n",
    "\n",
    "    colors = plt.cm.tab10.colors\n",
    "    for i, machine_index in enumerate(range(machines)):\n",
    "        machine_df = df[df['Machine'] == f'Machine {machine_index + 1}']\n",
    "        plt.broken_barh([(start, end - start) for start, end in zip(machine_df['Start'], machine_df['Finish'])],\n",
    "                        (i * 10, 9), facecolors=[colors[j % 10] for j in range(jobs)], edgecolor='black')\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.yticks([i * 10 + 4.5 for i in range(machines)],\n",
    "                [f'Machine {i + 1}' for i in range(machines)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Johnson **n** jobs **2** machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def johnson_method(processing_times):\n",
    "    jobs, machines = processing_times.shape\n",
    "    copy_processing_times = processing_times.copy()\n",
    "    maximum = processing_times.max() + 1\n",
    "    m1 = []\n",
    "    m2 = []\n",
    "    \n",
    "    if machines != 2:\n",
    "        raise Exception(\"Johson method only works with two machines\")\n",
    "        \n",
    "    for i in range(jobs):\n",
    "        minimum = copy_processing_times.min()\n",
    "        position = np.where(copy_processing_times == minimum)\n",
    "        \n",
    "        if position[1][0] == 0:\n",
    "            m1.append(position[0][0])\n",
    "        else:\n",
    "            m2.insert(0, position[0][0])\n",
    "        \n",
    "        copy_processing_times[position[0][0]] = maximum\n",
    "        \n",
    "    return m1+m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  8]\n",
      " [20 10]\n",
      " [19 17]\n",
      " [ 8 13]\n",
      " [21  6]\n",
      " [13 10]\n",
      " [21 12]] \n",
      "\n",
      "Best sequence found by Johnson is [3, 2, 6, 5, 1, 0, 4] with a makespan of 126.0\n",
      "Elapsed time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generate a random example to work with 7 jobs and 2 machines\n",
    "rnd_data = np.random.randint(size=(7,2), low=5, high=23)\n",
    "print(rnd_data, \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "sol = johnson_method(rnd_data)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f'Best sequence found by Johnson is {sol} with a makespan of {incremental_cost(np.array(rnd_data).T,sol)}')\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDS Heuristic [Campbell,Dudek and Smith ] : **n** jobs **m** machines (1970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python code for CDS heuristic\n",
    "\n",
    "def cds_heuristic(processing_times):\n",
    "    \n",
    "    \n",
    "    nb_machines, nb_jobs = processing_times.shape\n",
    "\n",
    "\n",
    "    best_cost = math.inf\n",
    "\n",
    "    \n",
    "    machine_1_times = np.zeros((nb_jobs,1))\n",
    "    machine_2_times = np.zeros((nb_jobs,1))\n",
    "    \n",
    "    \n",
    "    # iterate through the nb_machines-1 auxiliary n-job 2-machines problems\n",
    "\n",
    "\n",
    "\n",
    "    for k in range(nb_machines -1):\n",
    "        machine_1_times[:,0] += processing_times[:][k]\n",
    "        machine_2_times[:,0] += processing_times[:][-k-1]\n",
    "        \n",
    "        jn_times = np.concatenate((machine_1_times, machine_2_times), axis=1)\n",
    "        seq = johnson_method(jn_times)\n",
    "        cost = incremental_cost(jn_times.T,seq)\n",
    "        if cost < best_cost:\n",
    "            best_cost = cost\n",
    "            best_seq = seq\n",
    "    \n",
    "    return best_seq, best_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34 18 40 26 12]\n",
      " [35 37 23 39 25]\n",
      " [14 37 40 33 25]\n",
      " [45 18 14 14 42]\n",
      " [17 27 11 44 33]\n",
      " [36 19 32 24 26]\n",
      " [30 36 49 23 22]\n",
      " [20 20 24 11 21]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2, 4, 7, 3, 5, 1, 6, 0], 243.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_data = np.random.randint(size=(8,5), low=10, high=50)\n",
    "print(rnd_data, \"\\n\")\n",
    "cds_heuristic(rnd_data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = read_flow_shop_data('../Lab1/data/tai20_5.txt', 5, 20)\n",
    "comman_instance = instances[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of CDS:\n",
      "Best sequence is [14, 2, 8, 13, 16, 7, 6, 0, 18, 3, 10, 15, 11, 1, 4, 5, 19, 17, 9, 12] with a makespan of 1390.0.\n",
      "Elapsed time of 0.003493785858154297 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_solution,best_cost  = cds_heuristic(comman_instance)\n",
    "\n",
    "\n",
    "best_cost = incremental_cost(comman_instance,best_solution)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Results of CDS:')\n",
    "print(f'Best sequence is {best_solution} with a makespan of {best_cost}.')\n",
    "print(f'Elapsed time of {elapsed_time} seconds.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEH Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_jobs_in_descending_order_of_total_completion_time(processing_times):\n",
    "    total_completion_time = processing_times.sum(axis=1)\n",
    "    return np.argsort(total_completion_time, axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion(sequence, position, value):\n",
    "    new_seq = sequence[:]\n",
    "    new_seq.insert(position, value)\n",
    "    return new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neh_algorithm(processing_times):\n",
    "    ordered_sequence = order_jobs_in_descending_order_of_total_completion_time(processing_times)\n",
    "    # Define the initial order\n",
    "    J1, J2 = ordered_sequence[:2]\n",
    "    sequence = [J1, J2] if incremental_cost(processing_times.T,[J1, J2]) < incremental_cost(processing_times.T,[J2, J1]) else [J2, J1]\n",
    "    del ordered_sequence[:2]\n",
    "    # Add remaining jobs\n",
    "    for job in ordered_sequence:\n",
    "        Cmax = float('inf')\n",
    "        best_sequence = []\n",
    "        for i in range(len(sequence)+1):\n",
    "            new_sequence = insertion(sequence, i, job)\n",
    "            Cmax_eval = incremental_cost(processing_times.T,new_sequence)\n",
    "            if Cmax_eval < Cmax:\n",
    "                Cmax = Cmax_eval\n",
    "                best_sequence = new_sequence\n",
    "        sequence = best_sequence\n",
    "    return sequence, Cmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of NEH:\n",
      "Best sequence is [4, 2, 19, 10, 7, 5, 3, 8, 1, 12, 6, 18, 16, 9, 14, 15, 0, 17, 13, 11] with a makespan of 1284.0.\n",
      "Elapsed time of 0.04602694511413574 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_solution,best_cost  = neh_algorithm(instances[6][2].T)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Results of NEH:')\n",
    "print(f'Best sequence is {best_solution} with a makespan of {best_cost}.')\n",
    "print(f'Elapsed time of {elapsed_time} seconds.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAM Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_cost(processing_times, sequence):\n",
    "    _, num_machines = processing_times.shape\n",
    "    num_jobs = len(sequence)\n",
    "    completion_times = np.zeros((num_jobs, num_machines))\n",
    "    \n",
    "    # Calculate the completion times for the first machine\n",
    "    completion_times[0][0] = processing_times[sequence[0]][0]\n",
    "    for i in range(1, num_jobs):\n",
    "        completion_times[i][0] = completion_times[i-1][0] + processing_times[sequence[i]][0]\n",
    "    \n",
    "    # Calculate the completion times for the remaining machines\n",
    "    for j in range(1, num_machines):\n",
    "        completion_times[0][j] = completion_times[0][j-1] + processing_times[sequence[0]][j]\n",
    "        for i in range(1, num_jobs):\n",
    "            completion_times[i][j] = max(completion_times[i-1][j], completion_times[i][j-1]) + processing_times[sequence[i]][j]\n",
    "    \n",
    "    # Return the total completion time, which is the completion time of the last job in the last machine\n",
    "    return completion_times[num_jobs-1][num_machines-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_from_list_values(master: np.ndarray, values: list) -> list:\n",
    "    indexes = []\n",
    "    for element in values:\n",
    "        for i in range(master.size):\n",
    "            if master[i] == element and i not in indexes:\n",
    "                indexes.append(i)\n",
    "                continue\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ham_sol_1(Pi1: np.ndarray, Pi2: np.ndarray) -> list:\n",
    "    diff = Pi2 - Pi1\n",
    "    sol = np.argsort(diff, axis=0).tolist()\n",
    "    sol.reverse()       # in decreasing order\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ham_sol_2(Pi1: np.ndarray, Pi2: np.ndarray) -> list:\n",
    "\n",
    "    diff = Pi2 - Pi1\n",
    "    according_pi1 = np.argwhere(diff >= 0)\n",
    "    according_pi2 = np.argwhere(diff < 0)\n",
    "\n",
    "    # Order Pi1 in increasing order\n",
    "    Pi1_sorted= np.sort(Pi1[according_pi1], axis=None).tolist()\n",
    "    Pi1_list = indices_from_list_values(Pi1, Pi1_sorted)\n",
    "\n",
    "    # Order Pi2 in decreasing order\n",
    "    Pi2_sorted = np.sort(Pi2[according_pi2], axis=None).tolist()\n",
    "    Pi2_sorted.reverse()\n",
    "    Pi2_list = indices_from_list_values(Pi2, Pi2_sorted)\n",
    "\n",
    "    return Pi1_list + Pi2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ham_heuristic(processing_times: np.ndarray) -> list:\n",
    "    _ , m = processing_times.shape\n",
    "    left = processing_times[:, :int(m/2)]\n",
    "    right = processing_times[:, int(m/2):]\n",
    "\n",
    "    Pi1 = left.sum(axis=1)\n",
    "    Pi2 = right.sum(axis=1)\n",
    "\n",
    "    solution1 = ham_sol_1(Pi1, Pi2)\n",
    "    solution2 = ham_sol_2(Pi1, Pi2)\n",
    "    Cmax1 = incremental_cost(processing_times, solution1)\n",
    "    Cmax2 = incremental_cost(processing_times, solution2)\n",
    "    \n",
    "    if Cmax1 < Cmax2:\n",
    "        return solution1, Cmax1\n",
    "    else:\n",
    "        return solution2, Cmax2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST HAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of HAM:\n",
      "Best sequence is [2, 8, 16, 14, 18, 10, 1, 12, 15, 7, 13, 5, 0, 4, 9, 17, 3, 6, 19, 11] with a makespan of 1417.0.\n",
      "Elapsed time of 0.0015211105346679688 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_solution, best_cost  = ham_heuristic(benchmarks[0])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Results of HAM:')\n",
    "print(f'Best sequence is {best_solution} with a makespan of {best_cost}.')\n",
    "print(f'Elapsed time of {elapsed_time} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PALMER Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PalmerHeuristic:\n",
    "    def __init__(self, dist_mat):\n",
    "        self.dist_mat = dist_mat\n",
    "        self.c = None\n",
    "        self.ordre_opt = []\n",
    "        self.nb_machines = dist_mat.shape[0]\n",
    "        self.nb_jobs = dist_mat.shape[1]\n",
    "        self.weights = None\n",
    " \n",
    "\n",
    "    def init_weights(self):      #middle machine has a weight of 0 and it increases/decreases toward last/first machine at same rate (Example for 3 machines: the weights are w1 =-2 w2 =0 w3 =+2)\n",
    "        lst = np.array([ (2*i - 1 - self.nb_machines) for i in range(self.nb_machines)])\n",
    "        return lst - np.mean(lst)\n",
    "   \n",
    "\n",
    "    def compute_weighted_sum(self):       #Computing weighted sum for each job (Example for j1: w1*d11 + w2*d12 + w3*d13)\n",
    "        weighted_sum = []\n",
    "        for i in range(self.nb_jobs):\n",
    "            somme = np.dot(self.dist_mat[:,i],self.weights)\n",
    "            weighted_sum.append(somme)\n",
    "        return np.array(weighted_sum)\n",
    "   \n",
    "\n",
    "    def sum_per_machine(self):      #Find the sum of time of each machine\n",
    "        return self.dist_mat.sum(axis=1)\n",
    "                                 \n",
    "    \n",
    "    def update_c(self, c, ordre):         # Update the computation time to get the makespan\n",
    "        c[0][0] = self.dist_mat[0,ordre[0]]\n",
    "        for j in range(1,self.nb_machines):\n",
    "            c[0][j] = self.dist_mat[j,ordre[0]] + c[0][j-1]\n",
    "        for j in range (1, self.nb_jobs):\n",
    "            c[j][0] = self.dist_mat[0, ordre[j]] + c[j-1][0]\n",
    "        for i in range(1, self.nb_jobs):\n",
    "            for j in range(1,self.nb_machines):\n",
    "                c[i][j] = max([c[i-1][j],c[i][j-1]]) + self.dist_mat[j,ordre[i]]\n",
    "        return c \n",
    "\n",
    "    \n",
    "    def get_cmax(self):               # Cmax : makespan\n",
    "        return self.c[len(self.ordre_opt)-1][self.dist_mat.shape[0]-1]\n",
    "    \n",
    "    \n",
    "    def lower_bound(self):                     #Define the lower bound (upperbound is the cmax found)\n",
    "        lb = []\n",
    "        for i in range(self.nb_machines):\n",
    "            a = self.sum_per_machine()\n",
    "            if i == 0:\n",
    "                bound = a[i] + min(self.dist_mat.T[:,1:].sum(axis=1))\n",
    "            \n",
    "            elif i == (self.nb_machines -1) :\n",
    "                bound = a[i] + min(self.dist_mat.T[:,:i].sum(axis=1)) \n",
    "            \n",
    "            else :\n",
    "                bound = a[i] + min(self.dist_mat.T[:,:i].sum(axis=1)) + min(self.dist_mat.T[:,i+1])\n",
    "            \n",
    "            lb.append(bound)\n",
    "        return max(lb)\n",
    "    \n",
    "\n",
    "    def run(self):\n",
    "        self.weights = self.init_weights()\n",
    "        C = np.zeros((self.nb_jobs, self.nb_machines))\n",
    "        \n",
    "        self.c = C\n",
    "        a = self.compute_weighted_sum()\n",
    "        self.ordre_opt = np.argsort(a)[::-1] #argsort effectue le tri dans l'ordre ascendant donc on l'inverse\n",
    "    \n",
    "        self.update_c(self.c,self.ordre_opt)\n",
    "        lb = self.lower_bound()\n",
    "        print('optimal order for Palmer')\n",
    "        print(self.ordre_opt + 1)\n",
    "        print('\\nCmax: ' + str(self.get_cmax()))\n",
    "        print('Lower Bound: ' + str(lb))\n",
    "        print(self.c)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PALMER Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal order for Palmer\n",
      "[ 9 11 17 15 16 19  3  6 14  8  2  4  1  5 13  7 12 10 18 20]\n",
      "\n",
      "Cmax: 1384.0\n",
      "Lower Bound: 1232\n",
      "[[  27.   32.   89.  138.  207.]\n",
      " [ 103.  106.  113.  223.  309.]\n",
      " [ 135.  156.  182.  277.  367.]\n",
      " [ 147.  203.  266.  333.  414.]\n",
      " [ 224.  238.  313.  373.  501.]\n",
      " [ 292.  297.  390.  441.  569.]\n",
      " [ 307.  318.  439.  472.  589.]\n",
      " [ 343.  413.  484.  575.  624.]\n",
      " [ 372.  488.  529.  616.  673.]\n",
      " [ 410.  548.  571.  675.  716.]\n",
      " [ 493.  551.  660.  733.  789.]\n",
      " [ 564.  663.  678.  801.  886.]\n",
      " [ 618.  742.  758.  867.  944.]\n",
      " [ 695.  798.  887.  965. 1018.]\n",
      " [ 709.  871.  950. 1004. 1026.]\n",
      " [ 762.  970. 1030. 1043. 1096.]\n",
      " [ 853. 1031. 1032. 1052. 1168.]\n",
      " [ 940. 1087. 1151. 1236. 1249.]\n",
      " [1027. 1173. 1248. 1325. 1343.]\n",
      " [1121. 1250. 1290. 1356. 1384.]]\n"
     ]
    }
   ],
   "source": [
    "a = PalmerHeuristic(instances[0][2])\n",
    "a.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRSKE Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new PRSKE priority rule, all jobs are ordered by the non-increasing sum of : $$ AVG_i + STD_i + |SKE_i|$$ \n",
    "where:\n",
    "\n",
    "- $ AVG_i $ represents the average processing time of job _i_.\n",
    "- $ STD_i $ stands for the standard deviation of job _i_.\n",
    "- $ |SKE_i| $ denotes the absolute value of the skewness of job _i_.\n",
    "\n",
    "The parameters are defined as follows:\n",
    "\n",
    "- $$ AVG_i = \\frac{1}{m} \\sum_{k=1}^{m} t_{i,k}$$\n",
    "- $$ STD_i = \\sqrt{\\frac{1}{m-1} \\sum_{k=1}^{m} (t_{i,k} - AVG_i)^2} $$\n",
    "- $$ SKE_i = \\frac{\\frac{1}{m} \\sum_{k=1}^{m} (t_{i,k} - AVG_i)^3}{\\left({\\sqrt{\\frac{1}{m} \\sum_{k=1}^{m} (t_{i,k} - AVG_i)^2}}\\right)^3} $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ t_{i,k} $ represents the processing time of job _i_ on machine _k_.\n",
    "- $ m $ is the number of machines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AVG(processing_times):\n",
    "    return np.mean(processing_times, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STD(processing_times):\n",
    "    return np.std(processing_times, axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_SKE(processing_times):\n",
    "    \"\"\"\n",
    "    Calculates the skewness of job processing times across machines.\n",
    "    Return : Skewness values for each job\n",
    "    \n",
    "    \"\"\"\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "    skewness_values = []\n",
    "\n",
    "    \n",
    "    for i in range(num_jobs):\n",
    "        avg_processing_time = np.mean(processing_times[i,:])\n",
    "        numerateur = 0\n",
    "        denominateur = 0\n",
    "\n",
    "        for j in range(num_machines):\n",
    "            som = (processing_times[i,j] - avg_processing_time)\n",
    "            numerateur += som ** 3\n",
    "            denominateur += som ** 2\n",
    "\n",
    "        numerateur *= (1 / num_machines)\n",
    "        denominateur = (np.sqrt(denominateur * (1 / num_machines))) ** 3\n",
    "\n",
    "        skewness_values.append(numerateur / denominateur)\n",
    "        \n",
    "    return np.array(skewness_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRSKE(processing_times):\n",
    "    \"\"\"\n",
    "    Calculates the job sequence based on the PRSKE priority rule\n",
    "\n",
    "    \"\"\"\n",
    "    avg = AVG(processing_times)   # Calculate average processing times\n",
    "\n",
    "    std = STD(processing_times)   #Calculate standard deviation processing times\n",
    "\n",
    "    skw = np.abs(skewness_SKE(processing_times)) # Calculate Skewness \n",
    "\n",
    "    order = skw + std + avg  \n",
    "\n",
    "    # Sort in descending order\n",
    "    sorted_order = sorted(zip(order, list(range(processing_times.shape[0]))),reverse=True)\n",
    "\n",
    "    sequence = [job for _ , job in sorted_order]\n",
    "\n",
    "    incremental_cost_value = incremental_cost(processing_times, sequence)  # Calculte incremental_cost\n",
    "\n",
    "    return sequence,  incremental_cost_value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST PRSKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of PRSKE:\n",
      "Best sequence is [3, 17, 10, 1, 9, 11, 4, 6, 19, 18, 15, 5, 0, 12, 8, 14, 13, 7, 16, 2] \n",
      " with a makespan of 1593.0.\n",
      "Elapsed time of 0.004652738571166992 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_solution, best_cost  = PRSKE(benchmarks[0])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Results of PRSKE:')\n",
    "print(f'Best sequence is {best_solution} \\n with a makespan of {best_cost}.')\n",
    "print(f'Elapsed time of {elapsed_time} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHEN Heuristic (1983)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chen (1983) propose une heuristique qui consiste à procéder de la manière suivante :\n",
    "\n",
    "- on calcule la somme de temps opératoires $ S(i) $  pour chaque tâche i avec :\n",
    "$$ S(i) = \\sum_{k=1}^{m} t_{i,k} $$\n",
    "- on trouve la tâche c qui a la $ S(i) $ la plus importante et on enlève cette tâche de l'ensemble de tâches non ordonnancées.\n",
    "- on ordonnance les tâches qui ont $ P_{i1} <= P_{im} $ dans l'ordre croissant de $ P_{i1} $ et on obtient un ordonnancement partiel $ SA $.\n",
    "- on ordonnance les tâches qui ont $ P_{i1}>P_{im} $ dans l'ordre décroissant de $ P_{im} $ et on obtient un ordonnancement partiel $ SB $ .\n",
    "- on retient comme solution finale l'ordonnancement $ (SA, c, SB) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chen_heuristic(processing_times):\n",
    "\n",
    "    num_jobs = len(processing_times)\n",
    "    \n",
    "    sum_processing_times = [sum(processing_times[i]) for i in range(num_jobs)] # Calcule de la somme de temps opératoires S(i) pour chaque tâche i\n",
    "\n",
    "    job_max_sum = max(sum_processing_times)\n",
    "    job_c = sum_processing_times.index(job_max_sum)\n",
    "    \n",
    "    remaining_jobs = [i for i in range(num_jobs) if i != job_c]\n",
    "   \n",
    "    \n",
    "    sorted_jobs_le = sorted(remaining_jobs, key=lambda i: processing_times[i][0])\n",
    "    \n",
    "    sorted_jobs_gt = sorted(remaining_jobs, key=lambda i: processing_times[i][-1], reverse=True)\n",
    "   \n",
    "    S_a = [i for i in sorted_jobs_le if processing_times[i][0] <= processing_times[i][-1]]\n",
    "    S_b = [i for i in sorted_jobs_gt if processing_times[i][0] > processing_times[i][-1]]\n",
    "    \n",
    "    sequence = S_a + [job_c] + S_b\n",
    "    \n",
    "    incremental_cost_value = incremental_cost(processing_times, sequence)\n",
    "    \n",
    "    return sequence, incremental_cost_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Chen heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of CHEN:\n",
      "Best sequence is [14, 2, 8, 13, 16, 7, 6, 0, 18, 3, 10, 15, 4, 11, 1, 5, 19, 17, 9, 12] \n",
      " with a makespan of 1390.0.\n",
      "Elapsed time of 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "best_solution, best_cost  = chen_heuristic(benchmarks[0])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Results of CHEN:')\n",
    "print(f'Best sequence is {best_solution} \\n with a makespan of {best_cost}.')\n",
    "print(f'Elapsed time of {elapsed_time} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUPTA's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_makespan(processing_times, sequence):\n",
    "    n_jobs = len(sequence)\n",
    "    n_machines = len(processing_times[0])\n",
    "    end_time = [[0] * (n_machines + 1) for _ in range(n_jobs + 1)]\n",
    "    \n",
    "    for j in range(1, n_jobs + 1):\n",
    "        for m in range(1, n_machines + 1):\n",
    "            end_time[j][m] = max(end_time[j][m - 1], end_time[j - 1]\n",
    "                                 [m]) + processing_times[sequence[j - 1]][m - 1]\n",
    "\n",
    "    return end_time[n_jobs][n_machines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sum_processing(job_index, processing_times):\n",
    "    min_sum = np.inf\n",
    "    for i in range(processing_times.shape[1] - 1):\n",
    "        sum_for_pair = processing_times[job_index,\n",
    "                                        i] + processing_times[job_index, i + 1]\n",
    "        if sum_for_pair < min_sum:\n",
    "            min_sum = sum_for_pair\n",
    "    return min_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priority(job_index, processing_times):\n",
    "    diff = float(processing_times[job_index, 0] -\n",
    "                 processing_times[job_index, -1])\n",
    "    sign = (diff > 0) - (diff < 0)\n",
    "    return sign / min_sum_processing(job_index, processing_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gupta_heuristic(processing_times):\n",
    "    priorities = [calculate_priority(i, processing_times)\n",
    "                  for i in range(processing_times.shape[0])]\n",
    "    total_times = [np.sum(processing_times[i])\n",
    "                   for i in range(processing_times.shape[0])]\n",
    "    sequence = sorted(range(len(priorities)), key=lambda k: (priorities[k], total_times[k]))\n",
    "    best_makespan = calculate_makespan(processing_times,sequence)\n",
    "    return sequence, best_makespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUPTA TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of GUPTA:\n",
      "Best sequence is [10, 2, 8, 16, 14, 15, 7, 13, 0, 3, 18, 6, 4, 5, 9, 17, 1, 19, 12, 11] \n",
      " with a makespan of 1396.\n",
      "Elapsed time of 0.0009999275207519531 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "best_solution, best_cost  = gupta_heuristic(benchmarks[0])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Results of GUPTA:')\n",
    "print(f'Best sequence is {best_solution} \\n with a makespan of {best_cost}.')\n",
    "print(f'Elapsed time of {elapsed_time} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
